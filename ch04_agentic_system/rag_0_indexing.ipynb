{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e696dfe6-7696-4b95-861b-c0f388405c63",
   "metadata": {},
   "source": [
    "# RAG: Indexing\n",
    "\n",
    "This notebook shows you how to build a simple RAG system.\n",
    "\n",
    "We take an out-of-copyright geography text, chunk it, and store it in a vector database.\n",
    "\n",
    "Then, in the generation notebook, we ask questions and the RAG system finds us answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11739d13-72a7-43c1-be4a-b001f28aa6a3",
   "metadata": {},
   "source": [
    "## Set up.\n",
    "\n",
    "Install the necessary packages, set up the API keys etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a020c630-aa32-4f78-a92f-654485fcd795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4389be-f2e1-468e-866c-40a933b4c1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0403e3b7-1b11-49b7-81ed-a38d7b24ca82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROVIDER = \"Google\"\n",
    "#PROVIDER = \"OpenAI\"\n",
    "PERSIST_DIR = \"vectordb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2973efb3-40a0-46e4-bd56-252718baed2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PROVIDER == \"Google\":\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1)\n",
    "else:\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c85d7e-b67b-4e2e-8c88-5fb0210c77e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Getting the data\n",
    "\n",
    "We'll use an out-of-copyright geography textbook as our example. Normally, of course, you'll use documents relevant to your enterprise here.  We'll get the website, pull out the paragraphs and do some simple cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9532804d-484e-4181-8a1a-6fb4d9903f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import bs4\n",
    "DOC_URL=\"https://www.gutenberg.org/cache/epub/3772/pg3772-images.html\"\n",
    "html = urllib.request.urlopen(DOC_URL)\n",
    "paragraphs = [\" \".join(p.get_text().split()).strip() for p in bs4.BeautifulSoup(html, 'html.parser').find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9c67cf-016a-484a-8476-a7c95cd612d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74347a00-f666-455a-9602-1751a45a8e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Palæontological Relations of the Oolitic Strata.—Observations have already been made on the distinctness of the organic remains of the Oolitic and Cretaceous strata, and the proportion of species common to the different members of the Oolite. Between the Lower Oolite and the Lias there is a somewhat greater break, for out of 256 mollusca of the Upper Lias, thirty-seven species only pass up into the Inferior Oolite.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[1090]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ca977-759b-44e1-ba52-1f29dec1bbe1",
   "metadata": {},
   "source": [
    "## Step 2: Creating embeddings of the chunks and storing them in a vector database\n",
    "\n",
    "We were careful to split the text into paragraphs, so that each chunk is somewhat consistent in terms of topic. Another approach is to split into sentences. A third approach is to split into overlapping chunks of equivalent characters. Look at the available text splitters in langchain.\n",
    "For example:\n",
    "<pre>\n",
    "RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1dc9523-0d93-4417-9b26-c0631d0e124c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf $PERSIST_DIR  # from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495237e0-a985-42ac-b3a3-1400d4cb0ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "docs = [Document(page_content=p, metadata={\"source\": \"geography\", \"paragraph\": pno+1}) for pno, p in enumerate(paragraphs)]\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fafaad-c563-4581-b6f7-0fa9005ed440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18M\n",
      "drwxr-xr-x 2 jupyter jupyter 4.0K Jul 31 22:22 d25490e4-557b-431d-9c73-6132ad2cba6e\n",
      "-rw-r--r-- 1 jupyter jupyter  18M Jul 31 22:22 chroma.sqlite3\n"
     ]
    }
   ],
   "source": [
    "!ls -lrth $PERSIST_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd2b8a-7a96-476b-9861-ab85f8d0c62b",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "Look at [./rag_1_generation.ipynb](rag_1_generation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

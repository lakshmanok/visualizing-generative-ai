{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2425ad3-aabf-4af9-97e0-20aa2961611c",
   "metadata": {},
   "source": [
    "# Creating the finetuning training dataset\n",
    "\n",
    "This notebook prepares a dataset to train a model that will\n",
    "create a line in the style of a Shakespearean sonnet when given a single word.\n",
    "\n",
    "See [./finetuning_1_adaptertune.ipynb](./finetuning_1_adaptertune.ipynb) for the actual training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b59d7f-9a38-48ea-98ac-0f5099c2bab6",
   "metadata": {},
   "source": [
    "## Set up.\n",
    "\n",
    "Install the necessary packages, set up the API keys etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f556f-e1ac-4cc4-b928-b45b25c5a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcb575b-9f6f-407b-9680-0f2ed2dabf0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de62c6f-807a-489b-a597-754eaff28589",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download stop, obscene words\n",
    "\n",
    "Words that we should not index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85828ca8-0c1d-4a06-ab81-76609e98de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4365dee-e7af-4342-be59-e5f1f8c2b8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/en -O obscene.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5a7df3-4c17-4dd7-9a4c-2250fd4dece0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_as_set(filename):\n",
    "    with open(filename) as ifp:\n",
    "        words = ifp.readlines()\n",
    "        words = [word.strip() for word in words]\n",
    "        return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d017f3d3-6d3a-463d-bff8-8b37a1cd977a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = get_as_set('stopwords-en.txt')\n",
    "# add a few more Shakespearean words\n",
    "stopwords.update(['thy', 'thine', 'tis', 'thou'])\n",
    "obscene = get_as_set('obscene.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929fcbf3-f183-4044-bb75-caef58956752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asking', 'nu', 'gotten', 'past', 'way', 'ir', 'behind', 'gives', 'gmt', 'same']\n"
     ]
    }
   ],
   "source": [
    "#print(obscene)\n",
    "print(list(stopwords)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb495cb1-75a5-435b-9809-941ccf75703d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/orgtre/google-books-ngram-frequency/main/ngrams/1grams_english.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd25455b-b9e7-413c-9605-a38f44f73668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "word_freq = pd.read_csv('1grams_english.csv').set_index('ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b583a6f9-965c-4e51-8d67-723c6cfbb724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35043274.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.loc['remember']['freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ffee4-704b-4a01-8e74-8e7966cf6195",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download sonnets\n",
    "\n",
    "From Project Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec732bf-b4c5-4ac3-a901-84779b6c9cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://www.gutenberg.org/cache/epub/1041/pg1041.txt -O sonnets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcfc1230-ddd5-4666-bf77-6e0c5b2c33ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of Shakespeare's Sonnets\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head sonnets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a269414-1f4e-442b-9ee7-7e8ba041f297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From fairest creatures we desire increase,',\n",
       " 'That thereby beauty’s rose might never die,',\n",
       " 'But as the riper should by time decease,',\n",
       " 'His tender heir might bear his memory:',\n",
       " 'But thou, contracted to thine own bright eyes,',\n",
       " 'Feed’st thy light’s flame with self-substantial fuel,',\n",
       " 'Making a famine where abundance lies,',\n",
       " 'Thyself thy foe, to thy sweet self too cruel:',\n",
       " 'Thou that art now the world’s fresh ornament,',\n",
       " 'And only herald to the gaudy spring,',\n",
       " 'Within thine own bud buriest thy content,',\n",
       " 'And tender churl mak’st waste in niggarding:',\n",
       " 'Pity the world, or else this glutton be,',\n",
       " 'To eat the world’s due, by the grave and thee.',\n",
       " 'When forty winters shall besiege thy brow,',\n",
       " 'And dig deep trenches in thy beauty’s field,',\n",
       " 'Thy youth’s proud livery so gazed on now,',\n",
       " 'Will be a tatter’d weed of small worth held:',\n",
       " 'Then being asked, where all thy beauty lies,',\n",
       " 'Where all the treasure of thy lusty days;']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonnet_lines = []\n",
    "with open('sonnets.txt', 'r') as ifp:\n",
    "    # skip the first 25 or so lines as they are copyright etc.\n",
    "    for lineno in range(25):\n",
    "        next(ifp)\n",
    "    for line in ifp:\n",
    "        line = line.strip()\n",
    "        if len(line) > 30:\n",
    "            sonnet_lines.append(line)\n",
    "\n",
    "sonnet_lines[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c633bf-e17a-40c3-9e76-f8a446a34267",
   "metadata": {},
   "source": [
    "## Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9cd76bd-4838-4ae7-863f-acbb92612297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contracted', 'bright', 'eyes']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, sys\n",
    "\n",
    "def is_obscene(words):\n",
    "    for word in words:\n",
    "        if word in obscene:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_index_words(text):\n",
    "    words = re.sub(r'[^a-zA-Z]', ' ', text.lower()).split()\n",
    "    if is_obscene(words):\n",
    "        return [] # prune out the obscene text by not indexing them\n",
    "    else:\n",
    "        indexes = [word for word in words if word not in stopwords]\n",
    "        # no more than 3 index words\n",
    "        if len(indexes) > 3:\n",
    "            freq = [int(word_freq.loc[word]['freq']) if word in word_freq.index else sys.maxsize for word in indexes ]\n",
    "            zipped = sorted(zip(freq, indexes))\n",
    "            indexes = [x for _, x in list(zipped)[:3]]\n",
    "        return indexes\n",
    "\n",
    "get_index_words(sonnet_lines[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "111c5800-6d63-44a4-9c85-15e74f7f8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_lines = []\n",
    "for line in sonnet_lines:\n",
    "    index_words = get_index_words(line) # will prune out any line containing words that the LLMs might reject\n",
    "    for word in index_words:\n",
    "        indexed_lines.append({\n",
    "            \"input\": word,\n",
    "            \"output\": line\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63cb00ea-612b-4b40-ad64-98a9d49306ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'winter',\n",
       " 'output': 'But flowers distill’d, though they with winter meet,'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_lines[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36e5fa72-c604-4206-b6f5-bf19439b3cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(indexed_lines, open('indexed_sonnets.json', \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8de5aea5-c15c-448d-ab02-f4c6a486793e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"input\": \"creatures\",\n",
      "    \"output\": \"From fairest creatures we desire increase,\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"desire\",\n",
      "    \"output\": \"From fairest creatures we desire increase,\"\n",
      "  },\n",
      "  {\n"
     ]
    }
   ],
   "source": [
    "!head indexed_sonnets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5774cd7b-af84-4ae2-bf3f-90a05f4a3b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 598K Aug 14 00:22 indexed_sonnets.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh indexed_sonnets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e7948-cd14-418b-b411-b166cbe2e794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

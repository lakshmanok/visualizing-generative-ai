{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2425ad3-aabf-4af9-97e0-20aa2961611c",
   "metadata": {},
   "source": [
    "# Creating the finetuning training dataset\n",
    "\n",
    "This notebook uses a dataset of about 200K jokes scraped from Reddit r/dadjokes\n",
    "and indexes the joke.  The idea is that, given a word, the fine-tuned LLM should generate\n",
    "a joke that contains the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b59d7f-9a38-48ea-98ac-0f5099c2bab6",
   "metadata": {},
   "source": [
    "## Set up.\n",
    "\n",
    "Install the necessary packages, set up the API keys etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f556f-e1ac-4cc4-b928-b45b25c5a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcb575b-9f6f-407b-9680-0f2ed2dabf0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\");\n",
    "\n",
    "PROVIDER = \"Google\"\n",
    "#PROVIDER = \"OpenAI\"\n",
    "\n",
    "if PROVIDER == \"Google\":\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1)\n",
    "else:\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de62c6f-807a-489b-a597-754eaff28589",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download stop, obscene words\n",
    "\n",
    "Words that we should not index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85828ca8-0c1d-4a06-ab81-76609e98de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4365dee-e7af-4342-be59-e5f1f8c2b8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/en -O obscene.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5a7df3-4c17-4dd7-9a4c-2250fd4dece0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_as_set(filename):\n",
    "    with open(filename) as ifp:\n",
    "        words = ifp.readlines()\n",
    "        words = [word.strip() for word in words]\n",
    "        return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d017f3d3-6d3a-463d-bff8-8b37a1cd977a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = get_as_set('stopwords-en.txt')\n",
    "obscene = get_as_set('obscene.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929fcbf3-f183-4044-bb75-caef58956752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['formerly', 'cs', 'suggest', 'except', \"that'll\", 'whoever', 'fr', 'sb', 'v', \"we're\"]\n"
     ]
    }
   ],
   "source": [
    "#print(obscene)\n",
    "print(list(stopwords)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb495cb1-75a5-435b-9809-941ccf75703d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/orgtre/google-books-ngram-frequency/main/ngrams/1grams_english.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd25455b-b9e7-413c-9605-a38f44f73668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "word_freq = pd.read_csv('1grams_english.csv').set_index('ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b583a6f9-965c-4e51-8d67-723c6cfbb724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35043274.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.loc['remember']['freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ffee4-704b-4a01-8e74-8e7966cf6195",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download joke data and clean up the data\n",
    "\n",
    "Note: this is a scraped dataset. some of the jokes might be offensive (hopefully, after removing the low score ones and removing obscene words, the remainder are relatively clean).\n",
    "\n",
    "Download jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec732bf-b4c5-4ac3-a901-84779b6c9cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget --quiet https://raw.githubusercontent.com/taivop/joke-dataset/master/reddit_jokes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcfc1230-ddd5-4666-bf77-6e0c5b2c33ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \"score\": 10,\n",
      "        \"title\": \"Manager : So do you think you'd be a good waiter?\"\n",
      "    },\n",
      "    {\n",
      "        \"body\": \"I have a couple of ideas:\\n\\n1: Dinner\\n2: Movies\\n\\n1 or 2? 1.. 2..? 1..... or 2?\",\n",
      "        \"id\": \"5txs4x\",\n",
      "        \"score\": 14,\n",
      "        \"title\": \"An optometrist asks a woman out on a date\"\n",
      "    },\n",
      "    {\n"
     ]
    }
   ],
   "source": [
    "!head -500 reddit_jokes.json | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c28754-7388-4a10-bdbd-9503647be560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('reddit_jokes.json') as ifp:\n",
    "    reddit_jokes = json.load(ifp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d1a369-5824-458b-b48a-bc9d48065733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Manager : So do you think you'd be a good waiter? ... Me : well, you could say I bring a lot to the table.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_jokes = [f\"{joke['title']} ... {joke['body']}\" for joke in reddit_jokes if joke['score'] > 5]\n",
    "good_jokes[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c633bf-e17a-40c3-9e76-f8a446a34267",
   "metadata": {},
   "source": [
    "## Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9cd76bd-4838-4ae7-863f-acbb92612297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destroy', 'kid', 'housing']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, sys\n",
    "\n",
    "def is_obscene(words):\n",
    "    for word in words:\n",
    "        if word in obscene:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_index_words(joke):\n",
    "    words = re.sub(r'[^a-zA-Z]', ' ', joke.lower()).split()\n",
    "    if is_obscene(words):\n",
    "        return [] # prune out the obscene jokes by not indexing them\n",
    "    else:\n",
    "        indexes = [word for word in words if word not in stopwords]\n",
    "        # no more than 3 index words\n",
    "        if len(indexes) > 3:\n",
    "            freq = [int(word_freq.loc[word]['freq']) if word in word_freq.index else sys.maxsize for word in indexes ]\n",
    "            zipped = sorted(zip(freq, indexes))\n",
    "            indexes = [x for _, x in list(zipped)[:3]]\n",
    "        return indexes\n",
    "\n",
    "get_index_words(good_jokes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "111c5800-6d63-44a4-9c85-15e74f7f8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_jokes = []\n",
    "for joke in good_jokes:\n",
    "    index_words = get_index_words(joke) # will prune out the obscene jokes\n",
    "    for word in index_words:\n",
    "        indexed_jokes.append({\n",
    "            \"input\": word,\n",
    "            \"output\": joke\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63cb00ea-612b-4b40-ad64-98a9d49306ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'teeth', 'output': \"What's red and bad for your teeth? ... A Brick.\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_jokes[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36e5fa72-c604-4206-b6f5-bf19439b3cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(indexed_jokes, open('indexed_jokes.json', \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8de5aea5-c15c-448d-ab02-f4c6a486793e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"input\": \"destroy\",\n",
      "    \"output\": \"Remember when you were a kid and when you cried your parents said, \\\"I'll give you a reason to cry\\\"? ... I always thought they were gunna hit me, not that they were going to destroy the housing market 20 years later.\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"kid\",\n",
      "    \"output\": \"Remember when you were a kid and when you cried your parents said, \\\"I'll give you a reason to cry\\\"? ... I always thought they were gunna hit me, not that they were going to destroy the housing market 20 years later.\"\n",
      "  },\n",
      "  {\n"
     ]
    }
   ],
   "source": [
    "!head indexed_jokes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5774cd7b-af84-4ae2-bf3f-90a05f4a3b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 58M Aug 13 18:53 indexed_jokes.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh indexed_jokes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e7948-cd14-418b-b411-b166cbe2e794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
